# Challenge: Phase 10 - "The Brain Expansion" (Risiko-Analyse) ‚ö†Ô∏è

**Identit√§t:** Admin & Mentor (Red Team Mode)
**Ziel:** Kritische Schwachstellen im "Masken"-Konzept (Templates) aufdecken.

Hier sind die **drei gr√∂√üten Risiken**, warum dieses Konzept scheitern k√∂nnte:

## 1. Die "Struktur-Falle" (Type Safety vs. Flexibilit√§t) üèóÔ∏è

**Das Problem:**
Aktuell ist unser `T2Analyzer` extrem typensicher (`AnalysisResult`).
Er erwartet _zwingend_ `{ pbis: [], crs: [] }`.

Wenn wir Templates einf√ºhren (z.B. "Rechnung"), √§ndert sich die erwartete JSON-Struktur radikal (z.B. `{ iban: string, total: number }`).

**Warum es scheitern k√∂nnte:**

- **Keine Validierung mehr:** Wir m√ºssen im TypeScript-Code auf `any` oder extrem generische Typen (`Record<string, unknown>`) zur√ºckfallen.
- **Verlust der "Reflexion":** Unser `ReflexionEngine` pr√ºft aktuell hart auf PBI-IDs (Regex). Ein generischer Validator ("Pr√ºfe, ob das Feld 'iban' eine IBAN ist") ist extrem schwer zu bauen, ohne f√ºr jedes Template neuen Code zu schreiben.
- **Ergebnis:** Der Agent wird "dumm". Er validiert nicht mehr, ob die IBAN stimmt, sondern glaubt einfach dem LLM.

## 2. Das "Kontext-Problem" (Chunking vs. Globale Fakten) üß©

**Das Problem:**
In Phase 9 haben wir "Smart Chunking" eingef√ºhrt (Seite f√ºr Seite analysieren).
Das funktioniert perfekt f√ºr _lokale_ Probleme (ein Tippfehler auf Seite 5).

Aber Dokumente wie Vertr√§ge oder Rechnungen haben _globale_ Zusammenh√§nge:

- Seite 1: "Rechnungsbetrag: 50.000 ‚Ç¨"
- Seite 5: "Zahlungsziel: 30 Tage"

**Warum es scheitern k√∂nnte:**

- Unsere Logik bearbeitet Seite 1. Das LLM sieht "Betrag", aber kein "Ziel". Es gibt `{ amount: 50000, target: null }` zur√ºck.
- Dann bearbeitet es Seite 5. Es sieht "Ziel", aber keinen "Betrag". Es gibt `{ amount: null, target: "30 Tage" }` zur√ºck.
- **Merge-H√∂lle:** Am Ende haben wir zwei JSON-Objekte, die sich widersprechen oder schwer zu vereinen sind. Ein einfaches `Array.concat` (wie bei PBIs) funktioniert hier nicht mehr.

## 3. Die "Prompt-Fragilit√§t" (Garbage In, Garbage Out) üóëÔ∏è

**Das Problem:**
Wir verlagern die Intelligenz vom Code (`Analyzer.ts`) in Text-Dateien (`template.json`).
Das klingt gut ("User kann es √§ndern!"), ist aber gef√§hrlich.

**Warum es scheitern k√∂nnte:**

- **User sind keine Prompt Engineers:** Ein User schreibt: _"Such mir die Rechnungsnummer."_
- Das lokale Modell (Llama 3) braucht aber sehr pr√§zise Anweisungen (Few-Shot Examples, JSON-Schema), um valides JSON zu liefern.
- **Ergebnis:** Der Agent st√ºrzt ab oder liefert M√ºll, weil das User-Template nicht robust ist. Wir verlieren die Kontrolle √ºber die Qualit√§t der Analyse.

---

**Fazit:**
Das Konzept "Templates" klingt einfach, erfordert aber eine **komplette √úberarbeitung** von:

1.  Der **ReflexionEngine** (muss konfigurierbare Regeln/Regex unterst√ºtzen).
2.  Der **AggregationStrategy** (muss wissen, wie man Rechnungen merget vs. Listen merget).
